#  Information theory tools

## 癸 O projekcie

#### [ English version](#癸-about-the-project)

Programy s realizacj zada z przedmiotu `Teoria informacji i metody kompresji danych`, na VI semestrze studi贸w pierwszego stopnia na kierunku Informatyka na Politechnice Poznaskiej.

### ★ Lista program贸w

1. Przybli偶anie jzyka naturalnego na poziomie liter
    * Uruchom poleceniem `> python 01_NLA_letters.py "corpus.txt" "liczba znak贸w na wyjciu" "output.txt"`.
    * Program przetwarza tekst z korpusu (zostawia tylko sowa skadajce si wycznie z maych liter alfabetu), a nastpnie pozwala wygenerowa 5 r贸偶nych przybli偶e jzyka:
        * zerowego rzdu (bez 偶adnych prawdopodobiestw),
        * pierwszego rzdu (czsto liter zgodna z czstoci w korpusie),
        * na podstawie 藕r贸da Markova 1 rzdu (prawdopodobiestwo ka偶dej nowej litery zale偶y od jednej poprzedniej),
        * na podstawie 藕r贸da Markova 3 rzdu (prawdopodobiestwo ka偶dej nowej litery zale偶y od trzech poprzednich),
        * na podstawie 藕r贸da Markova 5 rzdu (prawdopodobiestwo ka偶dej nowej litery zale偶y od piciu poprzednich).
    * Program podaje zawsze redni dugo sowa z korpusu oraz w wygenerowanym tekcie. W zale偶noci od metody dodaje r贸wnie偶 dodatkowe informacje.
    * Program zapisuje w pliku wyjciowym przybli偶enie jzyka.
2. Przybli偶anie jzyka naturalnego na poziomie s贸w
    * Uruchom poleceniem `> python 02_NLA_words.py "corpus.txt" "liczba znak贸w na wyjciu" "output.txt"`.
    * Program przetwarza tekst z korpusu (rozdziela na sowa), a nastpnie pozwala wygenerowa 3 r贸偶ne przybli偶enia jzyka:
        * pierwszego rzdu (czsto s贸w zgodna z czstoci w korpusie); dodatkowo podaje 50 najczstszych s贸w z korpusu oraz ile % wszystkich s贸w stanowi 6000 i 30000 najczstszych s贸w,
        * na podstawie 藕r贸da Markova 1 rzdu (prawdopodobiestwo ka偶dego nowego sowa zale偶y od jednego poprzedniego),
        * na podstawie 藕r贸da Markova 2 rzdu (prawdopodobiestwo ka偶dego nowego sowa zale偶y od dw贸ch poprzednich).
    * Program zapisuje w pliku wyjciowym przybli偶enie jzyka.
3. Kompresje plik贸w
    * Uruchom poleceniem `> python 03_compression.py`.
    * Program pozwala kompresowa pliki trzema metodami:
        * kodowanie binarne o staej dugoci s贸w,
        * kodowanie Huffmana,
        * kodowanie metod LZW.
    * Program posiada interfejs tekstowy, w kt贸rym mo偶na wybra nastpujce opcje:
        * wczytanie pliku przeznaczonego do kompresji (w txt lub w dowolnym formacie w metodzie LZW),
        * wczytanie skompresowanego pliku w formacie bin,
        * wczytanie pliku z kodem,
        * zakodowanie i odkodowanie pliku,
        * przygotowanie samego kodu,
        * zapisanie zakodowanego i odkodowanego pliku,
        * zapisanie kodu,
        * wyczyszczenie rodowiska,
        * zmiana metody kodowania.

## 癸 About the project

#### [叼 Wersja polska](#癸-o-projekcie)

The programs are implementations of assignments from the `Information Theory` course during the 6th semester of the Bachelor's degree in Computer Science at Poznan University of Technology.

### ★ List of programs

1. Natural language approximation at the character level
    * Run with:  
      `> python 01_NLA_letters.py "corpus.txt" "number of characters at the output" "output.txt"`
    * The program processes the text corpus (retains only words composed exclusively of lowercase alphabetic letters), and then allows generating 5 types of language approximations:
        * zero-order (no probabilities used),
        * first-order (character frequency matches that in the corpus),
        * based on a first-order Markov source (probability of each new character depends on the previous one),
        * based on a third-order Markov source (depends on the previous three characters),
        * based on a fifth-order Markov source (depends on the previous five characters).
    * The program always outputs the average word length in the corpus and in the generated text. Depending on the method, additional information may be included.
    * The language approximation is saved to the output file.

2. Natural language approximation at the word level
    * Run with:  
      `> python 02_NLA_words.py "corpus.txt" "number of characters at the output" "output.txt"`
    * The program processes the corpus (splits text into words), and allows generating 3 types of language approximations:
        * first-order (word frequency matches that in the corpus); additionally, it lists the 50 most frequent words and shows what percentage of all words is covered by the top 6000 and 30000 words,
        * based on a first-order Markov source (probability of each new word depends on the previous one),
        * based on a second-order Markov source (depends on the previous two words).
    * The language approximation is saved to the output file.

3. File compression
    * Run with:  
      `> python 03_compression.py`
    * The program allows compressing files using three methods:
        * fixed-length binary coding,
        * Huffman coding,
        * LZW coding.
    * It features a text-based interface where you can:
        * load a file to compress (in txt or any format for LZW),
        * load a compressed file in `.bin` format,
        * load a file containing a code,
        * encode and decode a file,
        * prepare a code only,
        * save the encoded and decoded file,
        * save the code,
        * clear the environment,
        * change the coding method.
